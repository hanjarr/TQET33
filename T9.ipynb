{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utilities import Utils\n",
    "from feature_extraction import Feature\n",
    "from forest_regression import run_forest\n",
    "from forest_regression import RegressionForest\n",
    "from sklearn.externals import joblib\n",
    "from amrafile import amrafile as af\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "''' Init empty lists for storing reduced prototypes, reduced target and ncc'''\n",
    "reduced_prototypes, reduced_targets, reduced_masks, ncc = [], [], [], []\n",
    "reduced_mask = np.zeros((self._target_size), dtype = bool)\n",
    "\n",
    "''' Calculate ncc between reduced target and reduced prototype space. \n",
    "    Reduced spaces will be of size 2*reduced_size+1 to get an odd kernel and a well defined center point''' \n",
    "\n",
    "reduced_size = self._reduced_size\n",
    "\n",
    "for ind, poi in enumerate(prototype_pois):\n",
    "\n",
    "    z_lower = poi[0]-reduced_size[0]\n",
    "    z_upper = poi[0]+reduced_size[0]+1\n",
    "    y_lower = poi[1]-reduced_size[1]\n",
    "    y_upper = poi[1]+reduced_size[1]+1\n",
    "    x_lower = poi[2]-reduced_size[2]\n",
    "    x_upper = poi[2]+reduced_size[2]+1\n",
    "\n",
    "    prototype = prototype_data[ind]\n",
    "\n",
    "    ''' Extract reduced space from prototype and target'''\n",
    "    reduced_prototype = prototype[z_lower:z_upper, y_lower:y_upper, x_lower:x_upper]\n",
    "    reduced_target = self._water_data[z_lower:z_upper, y_lower:y_upper, x_lower:x_upper]\n",
    "\n",
    "    ''' Create binary mask of the reduced space'''\n",
    "    reduced_mask_copy = reduced_mask.copy()\n",
    "    reduced_mask_copy[z_lower:z_upper, y_lower:y_upper, x_lower:x_upper] = True\n",
    "\n",
    "    ''' Append reduced numpy arrays to lists'''\n",
    "    #reduced_prototypes.append(reduced_prototype)\n",
    "    #reduced_targets.append(reduced_target)\n",
    "    reduced_masks.append(reduced_mask_copy)\n",
    "\n",
    "            ''' Calculate ncc and store in lists'''\n",
    "            ncc.append(normalized_cross_correlation(reduced_prototype, reduced_target))\n",
    "\n",
    "        ''' Find index of poi which corresponds to highest ncc'''\n",
    "        poi_index = ncc.index(max(ncc))    \n",
    "\n",
    "        ''' Extract reduced data corresponding to highest ncc'''\n",
    "        reduced_mask = reduced_masks[poi_index]\n",
    "\n",
    "        reduced_water = np.reshape(self._water_data[reduced_mask], (2*self._reduced_size+1))\n",
    "        reduced_fat = np.reshape(self._fat_data[reduced_mask], (2*self._reduced_size+1))\n",
    "\n",
    "        return reduced_water, reduced_fat, reduced_mask, poi_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_target = '0019D'\n",
    "target_path = '/moria/data/DB/'+directory+test_target+'/wholebody_normalized_water_1_'+test_target+'.amra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground truth:\n",
      "[152 103 148]\n",
      "Feature extraction\n",
      "3.7029006481170654\n",
      "Run forest\n",
      "2.175846576690674\n",
      "5.20849553146\n",
      "25066\n",
      "[153 104 149]\n"
     ]
    }
   ],
   "source": [
    "''' Create utils class object '''\n",
    "utils = Utils(target_path, search_size, extension, poi)\n",
    "\n",
    "''' Init POI as just the ground truth + noise to reduce training time'''\n",
    "reduced_data, reduced_mask = utils.simple_search_reduction()\n",
    "\n",
    "''' Extract testing ground truth '''\n",
    "ground_truth = utils.extract_ground_truth(reduced_mask)\n",
    "\n",
    "''' Create feature object '''\n",
    "feature = Feature(nbr_of_filters, patch_size)\n",
    "\n",
    "''' Extract testing features '''\n",
    "test_features = feature.feature_extraction(reduced_data, filter_bank, filter_parameters)\n",
    "\n",
    "''' Run test data through forest '''\n",
    "regression = run_forest(estimators, test_features)\n",
    "\n",
    "poi_pos = utils.extract_poi_position(regression, reduced_mask)\n",
    "\n",
    "print(poi_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
